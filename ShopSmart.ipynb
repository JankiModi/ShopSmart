{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Imports\n",
    "\n",
    "import pandas as pd\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(search_term, pages,template):\n",
    "    \"\"\"\n",
    "    \n",
    "    The get_url function returns a list of urls for the searched phrase and the number of pages\n",
    "    \n",
    "    :search_term: The name or expression of the item you're looking for on Amazon \n",
    "    :pages: The number of pages you want to scrape (< maximum number of web pages shown)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # template= 'https://www.amazon.in/s?k={}&page={}'\n",
    "    template=template    \n",
    "    urls= []\n",
    "    \n",
    "    for i in range(1,pages):\n",
    "        search_term= search_term.replace(' ','+')\n",
    "        url= template.format(search_term, i)\n",
    "        urls.append(url)\n",
    "    return urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_record(item,website):\n",
    "    \"\"\"\n",
    "    \n",
    "    Scrape_record does scrape infos(Description, Rating, Reiew count ) of a particualar item an returned as a record\n",
    "    \n",
    "    :item: an html div where the infos are located\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #Product's description\n",
    "    if website=='amazon':\n",
    "        atag= item.h2.a\n",
    "        description= atag.text.strip()\n",
    "        \n",
    "        #Product's price\n",
    "        try:\n",
    "            price_parent= item.find('span','a-price')\n",
    "            price= price_parent.find('span', 'a-offscreen').text\n",
    "        except AttributeError:\n",
    "            return\n",
    "        \n",
    "        #Product's rating\n",
    "        try:\n",
    "            rating= item.i.text.strip()[:3]\n",
    "        except AttributeError:\n",
    "            rating= 'None'\n",
    "            \n",
    "        #Product's reiew count    \n",
    "        try:\n",
    "            review_count= item.find('span',{'class': 'a-size-base s-underline-text'}).text\n",
    "        except AttributeError:\n",
    "            review_count= 'None'\n",
    "        \n",
    "        record= (description, price, rating, review_count)\n",
    "    \n",
    "        return record\n",
    "    elif website=='flipkart':\n",
    "        description= item.find('a','s1Q9rs').text.strip()\n",
    "    \n",
    "    #Product's price\n",
    "        try:\n",
    "            price_parent= item.find('div','_30jeq3').text\n",
    "        except AttributeError:\n",
    "            return\n",
    "        \n",
    "        #Product's rating\n",
    "        try:\n",
    "            rating= item.find('div','_3LWZlK').text\n",
    "        except AttributeError:\n",
    "            rating= 'None'\n",
    "            \n",
    "        #Product's reiew count    \n",
    "        try:\n",
    "            review_count= item.find('span','_2_R_DZ').text[1:-1]\n",
    "        except AttributeError:\n",
    "            review_count= 'None'\n",
    "        \n",
    "        record= (description, price_parent, rating, review_count)\n",
    "        \n",
    "        return record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_pages(urls,website):\n",
    "    \"\"\"\n",
    "    The scrape_all_pages function loops over the urls and scrapes all items before saving the data in csv format.    \n",
    "    \n",
    "    :urls: list of urls generated by calling the get_url function\n",
    "    \"\"\"\n",
    "    records= [] \n",
    "    amazon=0 \n",
    "    flipkart=0\n",
    "    for url in urls:\n",
    "        headers= {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "        page= requests.get(url, headers=headers) \n",
    "        soup= BeautifulSoup(page.content,'html.parser')\n",
    "        if website=='amazon':\n",
    "            results= soup.find_all('div',{'data-component-type':'s-search-result'})\n",
    "            amazon=1\n",
    "        elif website=='flipkart':\n",
    "            results= soup.find_all('div',{'class':'_4ddWXP'})\n",
    "            flipkart=1\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        for item in results:\n",
    "            if amazon:\n",
    "                record= scrape_record(item,'amazon')\n",
    "            elif flipkart:\n",
    "                record= scrape_record(item,'flipkart')\n",
    "\n",
    "            if record:\n",
    "                records.append(record)\n",
    "        \n",
    "        # print(records)        \n",
    "        fileName=''\n",
    "    # Writing the rows into a csv file. If desired, this convertion set of code can be implemented as a function;\n",
    "    if website=='amazon':\n",
    "     \n",
    "        fileName='amazonData.csv'\n",
    "    elif website=='flipkart':\n",
    "        fileName='flipkartData1.csv'\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    with open(fileName, 'w', newline='', encoding='utf-8') as f:\n",
    "            \n",
    "            writer= csv.writer(f)\n",
    "            writer.writerow(['Description', 'Price', 'Rating', 'Review_count'])\n",
    "            writer.writerows(records)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_choice=input('Enter Category ')\n",
    "no_of_pages=int(input('Enter number of pages '))\n",
    "urls= get_url(user_choice,no_of_pages,'https://www.amazon.in/s?k={}&page={}')\n",
    "records= scrape_all_pages(urls,'amazon')\n",
    "df1= pd.read_csv('amazonData.csv')\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "urls=get_url(user_choice,no_of_pages,'https://www.flipkart.com/search?q={}&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page={}')\n",
    "records=scrape_all_pages(urls,'flipkart')\n",
    "df2=pd.read_csv('flipkartData1.csv')\n",
    "pd.set_option('display.max_rows',None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   \n",
    "from IPython.display import display_html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "df1_style = df1.style.set_caption(\"DF One\")\n",
    "df2_style = df2.style.set_caption(\"DF Two\")\n",
    "\n",
    "display_html(df1_style._repr_html_() + df2_style._repr_html_(), raw=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_item(website):\n",
    "    pd.set_option('expand_frame_repr', False)\n",
    "    pd.set_option('display.max_rows',None)\n",
    "    user_df = ''\n",
    "    if website == 'amazon':\n",
    "        user_df = df1.copy()\n",
    "    elif website == 'flipkart':\n",
    "        user_df = df2.copy()\n",
    "    elif website == 'merged':\n",
    "        df1['Website'] = 'Amazon'\n",
    "        df2['Website'] = 'Flipkart'\n",
    "        user_df = pd.concat([df1, df2], ignore_index=True).copy()\n",
    "\n",
    "    print('1. By rating')\n",
    "    print('2. By reviews count')\n",
    "    print('3. By price')\n",
    "    choice = int(input('Enter your choice: '))\n",
    "    \n",
    "    if choice == 1 :\n",
    "        # Sort DataFrame by 'Rating' column\n",
    "        df_sorted = user_df.sort_values(by='Rating', ascending=False)\n",
    "        print(df_sorted)\n",
    "    elif choice == 2:\n",
    "        user_df['Review_count'] = user_df['Review_count'].str.replace(',', '')\n",
    "\n",
    "        # Convert 'Review_count' column to integer\n",
    "        user_df['Review_count'] = pd.to_numeric(user_df['Review_count'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "        # Sort DataFrame by 'Review_count' column\n",
    "        df_sorted = user_df.sort_values(by='Review_count', ascending=False)\n",
    "\n",
    "        # Print the sorted DataFrame\n",
    "        print(df_sorted)\n",
    "    elif choice == 3:\n",
    "        user_df['Price'] = user_df['Price'].str.replace('â‚¹', '').str.replace(',', '')\n",
    "\n",
    "        # Convert 'Price' column to numeric\n",
    "        user_df['Price'] = pd.to_numeric(user_df['Price'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "        # Sort DataFrame by 'Price' column\n",
    "        df_sorted = user_df.sort_values(by='Price', ascending=True)\n",
    "\n",
    "        # Print the sorted DataFrame\n",
    "        print(df_sorted)\n",
    "    else:\n",
    "        print('Invalid input !!')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_differences2():\n",
    "    # Read data from CSV files into DataFrames\n",
    "    df_amazon = pd.read_csv(\"amazonData.csv\")\n",
    "    df_flipkart = pd.read_csv(\"flipkartData1.csv\")\n",
    "\n",
    "    # Extract price information\n",
    "    prices_amazon_copy = (\n",
    "        df_amazon[\"Price\"].str.replace(\"â‚¹\", \"\").str.replace(\",\", \"\").astype(float)\n",
    "    )\n",
    "    prices_flipkart_copy = (\n",
    "        df_flipkart[\"Price\"].str.replace(\"â‚¹\", \"\").str.replace(\",\", \"\").astype(float)\n",
    "    )\n",
    "\n",
    "    # Calculate mean prices\n",
    "    mean_price_amazon = prices_amazon_copy.mean()\n",
    "    mean_price_flipkart = prices_flipkart_copy.mean()\n",
    "\n",
    "    # Plot histogram for Amazon prices\n",
    "    plt.hist(\n",
    "        prices_amazon_copy, bins=20, alpha=0.5, color=\"blue\", label=\"Amazon Prices\"\n",
    "    )\n",
    "\n",
    "    # Plot histogram for Flipkart prices with adjusted parameters\n",
    "    plt.hist(\n",
    "        prices_flipkart_copy,\n",
    "        bins=20,\n",
    "        alpha=0.5,\n",
    "        color=\"green\",\n",
    "        label=\"Flipkart Prices\"\n",
    "    )\n",
    "\n",
    "    # Add vertical lines for mean prices\n",
    "    plt.axvline(\n",
    "        mean_price_amazon,\n",
    "        color=\"blue\",\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=1,\n",
    "        label=\"Amazon Mean Price: {:.2f}\".format(mean_price_amazon),\n",
    "    )\n",
    "    plt.axvline(\n",
    "        mean_price_flipkart,\n",
    "        color=\"green\",\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=1,\n",
    "        label=\"Flipkart Mean Price: {:.2f}\".format(mean_price_flipkart),\n",
    "    )\n",
    "\n",
    "    # Add labels, title, and legend\n",
    "    plt.xlabel(\"Price\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Comparison of Prices between Amazon and Flipkart\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Call the function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_differences():\n",
    "    # Read data from CSV files into DataFrames\n",
    "    df_amazon = pd.read_csv(\"amazonData.csv\")\n",
    "    df_flipkart = pd.read_csv(\"flipkartData1.csv\")\n",
    "\n",
    "    # Ask user for choice\n",
    "    print(\"Choose an option:\")\n",
    "    print(\"1. Histogram for Amazon prices\")\n",
    "    print(\"2. Histogram for Flipkart prices\")\n",
    "    print(\"3. Histogram for both Amazon and Flipkart prices\")\n",
    "    choice = int(input(\"Enter your choice (1/2/3): \"))\n",
    "\n",
    "    if choice == 1:\n",
    "        plot_histogram(df_amazon[\"Price\"], \"Amazon Prices\", \"blue\")\n",
    "    elif choice == 2:\n",
    "        plot_histogram(df_flipkart[\"Price\"], \"Flipkart Prices\", \"green\")\n",
    "    elif choice == 3:\n",
    "        bar_differences2()\n",
    "    else:\n",
    "\n",
    "        print(\"Invalid choice. Please choose 1, 2, or 3.\")\n",
    "def plot_histogram(prices, label, color):\n",
    "    # Extract price information\n",
    "    prices_copy = (\n",
    "        prices.str.replace(\"â‚¹\", \"\").str.replace(\",\", \"\").astype(float)\n",
    "    )\n",
    "\n",
    "    # Calculate mean price\n",
    "    mean_price = prices_copy.mean()\n",
    "\n",
    "    # Plot histogram\n",
    "    plt.hist(\n",
    "        prices_copy, bins=20, alpha=0.5, color=color, label=label\n",
    "    )\n",
    "\n",
    "    # Add vertical line for mean price\n",
    "    plt.axvline(\n",
    "        mean_price,\n",
    "        color=color,\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=1,\n",
    "        label=\"Mean Price: {:.2f}\".format(mean_price),\n",
    "    )\n",
    "\n",
    "    # Add labels, title, and legend\n",
    "    plt.xlabel(\"Price\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Histogram of Prices\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_choice = int(input(\"\"\"Choose an option:\n",
    "1. Sort  data\n",
    "2. Generate histogram of prices\n",
    "Enter your choice (1/2): \"\"\"))\n",
    "\n",
    "if user_choice == 1:\n",
    "    sort_choice = int(input(\"\"\"Choose an option:\n",
    "    1. Filter  Amazon Data\n",
    "    2. Filter  Flipkart Data\n",
    "    3. Filter  Both Amazon and Flipkart Data\n",
    "    Enter your choice (1/2/3): \"\"\"))\n",
    "\n",
    "    if sort_choice == 1:\n",
    "        sort_item('amazon')\n",
    "    elif sort_choice == 2:\n",
    "        sort_item('flipkart')\n",
    "    elif sort_choice == 3:\n",
    "        sort_item('merged')\n",
    "    else:\n",
    "        print('Invalid Input')\n",
    "\n",
    "elif user_choice == 2:\n",
    "    bar_differences()\n",
    "\n",
    "else:\n",
    "    print('Invalid Choice')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
